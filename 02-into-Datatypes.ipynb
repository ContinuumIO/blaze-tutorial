{
 "metadata": {
  "name": "",
  "signature": "sha256:1e53bf7d5d6c8d85f6bd14e51b0a079bc57d15e5ebf89e00d128e394e2561bcf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"images/blaze_med.png\" alt=\"Blaze Logo\"\n",
      "                                align=\"right\"\n",
      "                                width=\"30%\">\n",
      "\n",
      "# Getting started with `into`\n",
      "\n",
      "* Full tutorial available at http://github.com/ContinuumIO/blaze-tutorial\n",
      "* Install software with `conda install -c blaze blaze`"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Datatypes for Performance tuning\n",
      "\n",
      "*  *Do we store these as integers or floats?  `int32` or `int64`?  `int8`?*\n",
      "*  *Do we store times as datetimes or as strings?*\n",
      "*  *Do we store these strings as variable length or fixed length*?\n",
      "*  *Do we know how large this array will be?*\n",
      "\n",
      "As we encode values as bits we make choices; those choices can affect performance.  We encode how to convert values to bits and back as a *datatype*.  You've seen data types before in many forms including C types like `long`, `double` and `double[100]`, numpy dtypes like `i4` and `f8` or Python types like `int`, and `float`.  Other systems like SQL, HDF5, etc. have similar datatype systems with different names.\n",
      "\n",
      "To manage datatypes across different systems we use `datashape` a datatype system that maps cleanly on to all systems with which `into` interacts.  This one system can translate into any of the others.\n",
      "\n",
      "In this section we'll talk about the following\n",
      "\n",
      "1.  How to discover the datatype of your data, no matter how it is stored\n",
      "2.  Minor tweaks you can do to that datatype to improve performance in certain storage systems\n",
      "3.  How to create new datasets easily"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.1  DataShape and `discover`\n",
      "\n",
      "We introduce datashape, an all-encompassing datatype language, and `discover`, a function that does all of the work for you.\n",
      "\n",
      "The discover function returns the datashape of an object.  Lets look at a few examples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from into import discover\n",
      "discover(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "discover([1, 2, 3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "discover([[1, 2, 3],\n",
      "          [4, 5, 6]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "discover([{'x': 1, 'y': 1.0},\n",
      "          {'x': 2, 'y': 2.0},\n",
      "          {'x': 3, 'y': 3.0}])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "discover(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By looking closely at these examples we see the structure of datashape.  Elements have types like `int64` or `string`.  Records/structs/groups of elements have record dtypes like `{x: int64, y: float64}`.  Lengths of collections are encoded by numbers like `3 * ` for \"three of\" or `2 * 3 * ` for \"a two-by-three grid of\"."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Exercise\n",
      "\n",
      "Construct data with the following datashapes.  Use any container type (e.g. `list`, `pd.DataFrame`, `np.ndarray`).\n",
      "\n",
      "    2 * int64\n",
      "    2 * string\n",
      "    {name: string, id: int}\n",
      "    datetime\n",
      "    {name: string, id: int, payments: 2 * datetime}\n",
      "    2 * {name: string, id: int, payments: 2 * datetime}\n",
      "    5 * 5 * 5 * float32\n",
      "    \n",
      "Use `discover` to verify your answers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Should be 2 * int64\n",
      "discover([1, 2])  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Discover doesn't care about storage format\n",
      "\n",
      "The `discover` function doesn't care if your data lives in a Python list, Pandas DataFrame, NumPy Array, CSV file, PySpark RDD, or SQL database.  \n",
      "\n",
      "In other words, using `into` preserves datashape."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "discover(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = into(np.ndarray, df)\n",
      "discover(x)  # different container, same datashape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = into('sqlite:///:memory:::mydf', df)\n",
      "discover(t)  # different container, mostly the same datashape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Discover works on nested structures\n",
      "\n",
      "Call discover on a single table of our baseball statistics database."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "salaries = resource('sqlite:///data/lahman2013.sqlite::salaries')\n",
      "discover(salaries)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And then call it on the entire database"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db = resource('sqlite:///data/lahman2013.sqlite')\n",
      "discover(db)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.2 Tweaking Datashapes for Performance\n",
      "\n",
      "Some storage systems don't cleanly support some datashapes.  For example\n",
      "\n",
      "1.  SQL doesn't support nested data\n",
      "2.  HDF5 doesn't cleanly support datetimes\n",
      "3.  Variable length strings are often costly in binary stores\n",
      "4.  NumPy has poor missing value support\n",
      "\n",
      "Because of this we sometimes want to slightly change a datashape during migration."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fixed Length Strings\n",
      "\n",
      "A common example is the use of strings with a known maximum length, called \"fixed length strings,\" and strings with particular character encodings, like ASCII or UTF-8.\n",
      "\n",
      "Consider moving the following data, including strings, into a numpy array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [{'name': 'Alice', 'balance': 100},\n",
      "        {'name': 'Bob',   'balance': 200}]\n",
      "into(np.ndarray, data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the dtype for the `name` field is `'O'` for Python object type.  NumPy doesn't support arbitrary length strings and putting raw Python objects into a NumPy array can hurt performance.  So we choose a maximum length and tell that to into with a datashape.\n",
      "\n",
      "So how do we construct a datashape?  We could write it out by hand, but that is error prone.  Instead, we ask for the datashape of `data`, then copy-paste, making a small adjustment"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "discover(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from into import dshape\n",
      "ds = dshape(\"2 * {balance: int64, name: string[10]}\") # max length of 10\n",
      "\n",
      "into(np.ndarray, data, dshape=ds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note the new type, `U10`, meaning Unicode of length ten or less.  Our data happens to be ASCII, so we'll specialize our datashape even more."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds = dshape(\"2 * {balance: int64, name: string[10, 'ascii']}\") # max length of 10\n",
      "into(np.ndarray, data, dshape=ds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Exercise\n",
      "\n",
      "Move the data in `'data/iris.csv'` to the HDF5 dataset, `'data/myfile.hdf5::/iris'`.  Annotate the datatype of the `species` column to be ASCII with maximum length 30."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csv = resource('data/iris.csv')\n",
      "discover(csv)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Adding more metadata with DataShape\n",
      "\n",
      "Sometimes we store data in formats that lack metadata.  Adding a datashape can help to fill in these gaps.\n",
      "\n",
      "For example we might want to put the following latitude-longitude pairs into a DataFrame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = [(33.1, -89.2), (37, -141.5), (41, -120.5)]\n",
      "into(pd.DataFrame, data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that, because our original data was stored in a format that didn't include the column names, the output lacks them as well.  We complement our data with a datashape."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds = dshape('var * {lat: float64, long: float64}')\n",
      "into(pd.DataFrame, data, dshape=ds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Create new datasets with `resource` and datashape\n",
      "\n",
      "In the last section we used `resource` to acquire existing datasets from string URIs.  \n",
      "\n",
      "We also use the `resource` function to create new datasets given a URI and a datashape."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Example\n",
      "\n",
      "We create a new HDF5 dataset to store 100 by 100 integers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds = dshape('100 * 100 * int64')\n",
      "dset = resource('myfile.hdf5::/x', dshape=ds)\n",
      "dset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Exercise\n",
      "\n",
      "Create a new SQLite table named `transactions` in `'data/my.db'` with the following datashape\n",
      "\n",
      "    var * {name: string, balance: int, timestamp: datetime}\n",
      "    \n",
      "Here `var` stands for \"variable length\" or generally \"a dimension to which we don't know a fixed size.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that you could also have built this table using raw SQLAlchemy code.  Knowing datashape lets you skip learning many libraries like SQLAlchemy and H5Py for simple tasks.  `into` serves as a single interface over many useful libraries."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sqlalchemy as sa\n",
      "\n",
      "engine = sa.create_engine('sqlite:///data/my.db')\n",
      "metadata = sa.MetaData(engine)\n",
      "transactions = sa.Table('transactions', metadata,\n",
      "                        sa.Column('name', sa.String),\n",
      "                        sa.Column('balance', sa.Integer),\n",
      "                        sa.Column('timestamp', sa.DateTime))\n",
      "transactions.create()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}